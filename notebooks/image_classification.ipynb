{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsswkwk/turbo-chainsaw/blob/feature-add-image-classification/notebooks/image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 画像分類（Image Classification）\n",
        "入力した画像情報を「形」や「模様」、「色」など特徴量に分解し、入力情報から対象物を判定できるように対応付けを行う\n",
        "\n",
        "#### 畳み込み層\n",
        "特徴を抽出する層\n",
        "\n",
        "#### プーリング層\n",
        "画像サイズを小さくする層\n",
        "\n",
        "<br>\n",
        "\n",
        "## 画像分類のアーキテクチャ\n",
        "\n",
        "#### CNN（Convolutional Neural Network）\n",
        "畳み込みニューラルネットワーク（CNNまたはConvNet）は、畳み込みを使用しているニューラルネットワークの総称\n",
        "\n",
        "#### ResNet\n",
        "残差ニューラルネットワーク（ResNet）は、ウェイト層が層入力を参照して残差関数を学習する深層学習モデル\n",
        "\n",
        "#### VGG16\n",
        "ImageNetと呼ばれる大規模画像データセットで学習された16層(畳み込み13層、フル結合3層)からなる畳み込みニューラルネットワーク(CNN)\n",
        "\n",
        "#### Efficient Net\n",
        "複合スケーリング手法を用いて、ネットワークの幅、深さ、解像度を同時に最適化し、より少ないパラメータ数で高い精度を持つCNN\n"
      ],
      "metadata": {
        "id": "wm_anjAZ6g32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, applications\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# CIFAR-10データセットの読み込み\n",
        "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
        "# CIFAR-10のクラスラベル\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# データの前処理（画素値を0-1の範囲に正規化）\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# データ拡張\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class ResizeImage(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "\n",
        "  def call(self, image):\n",
        "    image = tf.image.resize(image, (224, 224))\n",
        "    return image\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config()\n",
        "    return config\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "    return cls(**config)\n",
        "\n",
        "\n",
        "class ImageClassificationModelBase:\n",
        "  def __init__(self, x_train, y_train, x_test, y_test, filepath):\n",
        "    self.filename = filepath.split('/')[-1]\n",
        "    self.name = self.filename.split('.')[0]\n",
        "    if os.path.exists(filepath):\n",
        "      self.model = tf.keras.models.load_model(filepath)\n",
        "    else:\n",
        "      self._build()\n",
        "      # optimizer: 最適化アルゴリズム, loss: 損失関数, metrics: 評価指標\n",
        "      self._compile()\n",
        "      history = self._fit(x_train, y_train, x_test, y_test)\n",
        "      self.model.save(self.filename)\n",
        "\n",
        "  def evaluate(self, x_test,  y_test):\n",
        "    test_loss, test_acc = self.model.evaluate(x_test,  y_test, verbose=2)\n",
        "    print(f'\\n{self.name}: Test accuracy: {test_acc}')\n",
        "\n",
        "  def predict(self, x):\n",
        "    return self.model.predict(np.expand_dims(x, axis=0))\n",
        "\n",
        "  def _build(self):\n",
        "    pass\n",
        "\n",
        "  def _compile(self):\n",
        "    self.model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "\n",
        "  def _fit(self, x_train, y_train, x_test, y_test):\n",
        "    history = self.model.fit(\n",
        "      datagen.flow(x_train, y_train, batch_size=32),\n",
        "      batch_size=32,\n",
        "      epochs=10,\n",
        "      validation_data=(x_test, y_test))\n",
        "    return history\n",
        "\n",
        "\n",
        "\n",
        "class CnnModel(ImageClassificationModelBase):\n",
        "  def _build(self):\n",
        "    self.model = models.Sequential()\n",
        "    self.model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    self.model.add(layers.MaxPooling2D((2, 2)))\n",
        "    self.model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    self.model.add(layers.MaxPooling2D((2, 2)))\n",
        "    self.model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    self.model.add(layers.Flatten())\n",
        "    self.model.add(layers.Dense(64, activation='relu'))\n",
        "    self.model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "class ResNetModel(ImageClassificationModelBase):\n",
        "  def _build(self):\n",
        "    # ResNet50モデルの読み込み（ImageNetで事前学習済み）\n",
        "    # ImageNet:\n",
        "    # 物体認識ソフトウェアの研究において、ソフトウェアの最適化や性能の評価等に\n",
        "    # 用いるために設計された、大規模な画像データセット\n",
        "    resnet_model = applications.ResNet50(weights='imagenet', include_top=False, input_shape=(224,224, 3))\n",
        "    resnet_model.trainable = True\n",
        "    inputs = layers.Input(shape=(32, 32, 3))\n",
        "\n",
        "    # ResNet50の出力層をCIFAR-10用に変更\n",
        "    # 事前学習済みのResNet50モデルに、CIFAR-10のクラス数に対応する全結合層を追加\n",
        "    x = ResizeImage()(inputs) # 入力画像の大きさをモデルに合わせる\n",
        "    x = resnet_model(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "    self.model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "\n",
        "class Vgg16Model(ImageClassificationModelBase):\n",
        "  def _build(self):\n",
        "    vgg16_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(224,224, 3))\n",
        "    vgg16_model.trainable = True\n",
        "    inputs = layers.Input(shape=(32, 32, 3))\n",
        "\n",
        "    x = ResizeImage()(inputs) # 入力画像の大きさをモデルに合わせる\n",
        "    x = vgg16_model(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "    self.model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  def _compile(self):\n",
        "    self.model.compile(\n",
        "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.09),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "\n",
        "\n",
        "class EfficientNetModel(ImageClassificationModelBase):\n",
        "  def _build(self):\n",
        "    efficientnet_model = applications.EfficientNetB5(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "    efficientnet_model.trainable = True\n",
        "    inputs = layers.Input(shape=(32, 32, 3))\n",
        "\n",
        "    x = ResizeImage()(inputs) # 入力画像の大きさをモデルに合わせる\n",
        "    x = efficientnet_model(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x) # GlobalAveragePooling2Dを追加\n",
        "    x = layers.Dropout(0.5)(x) # 学習済みモデルの出力付近のレイヤー(トップレイヤー)は不要なので取り除く\n",
        "    outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "    self.model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "\n",
        "  def _compile(self):\n",
        "    self.model.compile(\n",
        "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.025),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# CNN\n",
        "cnn_model = CnnModel(x_train, y_train, x_test, y_test, '/content/cnn.keras')\n",
        "cnn_model.evaluate(x_test, y_test)\n",
        "\n",
        "# ResNet\n",
        "resnet_model = ResNetModel(x_train, y_train, x_test, y_test, '/content/resnet.keras')\n",
        "resnet_model.evaluate(x_test, y_test)\n",
        "\n",
        "# VGG16\n",
        "vgg16_model = Vgg16Model(x_train, y_train, x_test, y_test, '/content/vgg16.keras')\n",
        "vgg16_model.evaluate(x_test, y_test)\n",
        "\n",
        "# Efficient Net\n",
        "effnet_model = EfficientNetModel(x_train, y_train, x_test, y_test, '/content/efficientnet.keras')\n",
        "effnet_model.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGnPN0oe6ynR",
        "outputId": "7b9f422e-1c7a-4502-eb30-33cf81b4aef1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "313/313 - 3s - 11ms/step - accuracy: 0.6333 - loss: 1.0415\n",
            "\n",
            "cnn: Test accuracy: 0.6333000063896179\n",
            "313/313 - 33s - 105ms/step - accuracy: 0.8153 - loss: 0.6274\n",
            "\n",
            "resnet: Test accuracy: 0.8152999877929688\n",
            "313/313 - 63s - 202ms/step - accuracy: 0.9093 - loss: 0.2724\n",
            "\n",
            "vgg16: Test accuracy: 0.9093000292778015\n",
            "313/313 - 61s - 196ms/step - accuracy: 0.9034 - loss: 0.3373\n",
            "\n",
            "efficientnet: Test accuracy: 0.9034000039100647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = random.randint(0, len(x_test) - 1)\n",
        "\n",
        "plt.imshow(x_test[index])\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "def print_checking_answer(model, x, y):\n",
        "  predicted_label = np.argmax(model.predict(x))\n",
        "  actual_label = np.argmax(y)\n",
        "  print(f'\\n{model.name}: Prediction: {class_names[predicted_label]}, Actual: {class_names[actual_label]}')\n",
        "\n",
        "for model in [cnn_model, resnet_model, vgg16_model, effnet_model]:\n",
        "  print_checking_answer(model, x_test[index], y_test[index])\n"
      ],
      "metadata": {
        "id": "NnLvLQDA-6E6",
        "outputId": "c889d916-3d84-4c3b-91ae-5dbf3cd15042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\n",
            "cnn: Prediction: deer, Actual: deer\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\n",
            "resnet: Prediction: deer, Actual: deer\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\n",
            "vgg16: Prediction: deer, Actual: deer\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\n",
            "efficientnet: Prediction: deer, Actual: deer\n"
          ]
        }
      ]
    }
  ]
}