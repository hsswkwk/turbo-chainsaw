{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsswkwk/turbo-chainsaw/blob/feature-add-image-classification/notebooks/image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 画像分類（Image Classification）\n",
        "入力した画像情報を「形」や「模様」、「色」など特徴量に分解し、入力情報から対象物を判定できるように対応付けを行う\n",
        "\n",
        "## CNN（Convolutional Neural Network）\n",
        "畳み込みニューラルネットワーク（CNNまたはConvNet）は、畳み込みを使用しているニューラルネットワークの総称\n",
        "\n",
        "## ResNet\n",
        "残差ニューラルネットワーク（ResNet）は、ウェイト層が層入力を参照して残差関数を学習する深層学習モデル\n",
        "\n",
        "## VGG16\n",
        "ImageNetと呼ばれる大規模画像データセットで学習された16層(畳み込み13層、フル結合3層)からなる畳み込みニューラルネットワーク(CNN)\n",
        "\n",
        "## Efficient Net\n",
        "複合スケーリング手法を用いて、ネットワークの幅、深さ、解像度を同時に最適化し、より少ないパラメータ数で高い精度を持つCNN"
      ],
      "metadata": {
        "id": "wm_anjAZ6g32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, applications\n",
        "\n",
        "# CIFAR-10データセットの読み込み\n",
        "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
        "# データの前処理（画素値を0-1の範囲に正規化）\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)  ##\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)  ##\n",
        "\n",
        "# CNN\n",
        "if os.path.exists('/content/cnn.keras'):\n",
        "  cnn_model = tf.keras.models.load_model('/content/cnn.keras')\n",
        "else:\n",
        "  # CNNモデルの構築\n",
        "  print(\"CNN model not found. Fit CNN model\")\n",
        "  cnn_model = models.Sequential()\n",
        "  cnn_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "  cnn_model.add(layers.MaxPooling2D((2, 2)))\n",
        "  cnn_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  cnn_model.add(layers.MaxPooling2D((2, 2)))\n",
        "  cnn_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  cnn_model.add(layers.Flatten())\n",
        "  cnn_model.add(layers.Dense(64, activation='relu'))\n",
        "  cnn_model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "  # モデルのコンパイル\n",
        "  # optimizer: 最適化アルゴリズム, loss: 損失関数, metrics: 評価指標\n",
        "  cnn_model.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  # モデルの学習\n",
        "  history = cnn_model.fit(x_train, y_train, batch_size=256, epochs=10,\n",
        "                     validation_data=(x_test, y_test))\n",
        "\n",
        "  cnn_model.save('cnn.keras')\n",
        "\n",
        "# モデルの評価\n",
        "test_loss, test_acc = cnn_model.evaluate(x_test,  y_test, verbose=2)\n",
        "print(f'\\nCNN: Test accuracy: {test_acc}')\n",
        "\n",
        "\n",
        "# ResNet\n",
        "if os.path.exists('/content/resnet.keras'):\n",
        "  resnet_model = tf.keras.models.load_model('/content/resnet.keras')\n",
        "else:\n",
        "  # ResNet50モデルの読み込み（ImageNetで事前学習済み）\n",
        "  # ImageNet:\n",
        "  # 物体認識ソフトウェアの研究において、ソフトウェアの最適化や性能の評価等に\n",
        "  # 用いるために設計された、大規模な画像データセット\n",
        "  resnet_pre_model = applications.ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "  # ResNet50の出力層をCIFAR-10用に変更\n",
        "  # 事前学習済みのResNet50モデルに、CIFAR-10のクラス数に対応する全結合層を追加\n",
        "  resnet_model = models.Sequential()\n",
        "  resnet_model.add(resnet_pre_model)\n",
        "  resnet_model.add(layers.Flatten())\n",
        "  resnet_model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "  # モデルのコンパイル\n",
        "  resnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  # モデルの学習\n",
        "  # バッチサイズ: モデルが一度に処理するデータの量\n",
        "  # エポック数: データセット全体を何回繰り返して学習するか\n",
        "  resnet_model.fit(x_train, y_train, batch_size=256, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "  resnet_model.save('resnet.keras')\n",
        "\n",
        "# モデルの評価\n",
        "loss, accuracy = resnet_model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f'\\nResNet: Test Accuracy: {accuracy}')\n",
        "\n",
        "\n",
        "\n",
        "# # VGG16\n",
        "# # VGG16モデルの読み込み（ImageNetで事前学習済み）\n",
        "# vgg16_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# # CIFAR-10データセットの読み込み\n",
        "# (x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
        "\n",
        "# # データの前処理\n",
        "# x_train = x_train.astype('float32') / 255.0\n",
        "# x_test = x_test.astype('float32') / 255.0\n",
        "# y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "# y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# # VGG16の出力層をCIFAR-10用に変更\n",
        "# model = models.Sequential()\n",
        "# model.add(vgg16_model)\n",
        "# model.add(layers.Flatten())\n",
        "# model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "# # モデルのコンパイル\n",
        "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # モデルの学習\n",
        "# model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# # モデルの評価\n",
        "# loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "# print(f'Test Accuracy: {accuracy}')\n",
        "\n",
        "\n",
        "# # Efficient Net\n",
        "# # EfficientNetB0モデルの読み込み（ImageNetで事前学習済み）\n",
        "# efficientnet_model = applications.EfficientNetB0(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# # CIFAR-10データセットの読み込み\n",
        "# (x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
        "\n",
        "# # データの前処理\n",
        "# x_train = x_train.astype('float32') / 255.0\n",
        "# x_test = x_test.astype('float32') / 255.0\n",
        "# y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "# y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# # EfficientNetB0の出力層をCIFAR-10用に変更\n",
        "# model = models.Sequential()\n",
        "# model.add(efficientnet_model)\n",
        "# model.add(layers.GlobalAveragePooling2D())  # GlobalAveragePooling2Dを追加\n",
        "# model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# # モデルのコンパイル\n",
        "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # モデルの学習\n",
        "# model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# # モデルの評価\n",
        "# loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "# print(f'Test Accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGnPN0oe6ynR",
        "outputId": "c1ad91e1-aa3a-4789-803d-20566b80935a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - 4ms/step - accuracy: 0.6695 - loss: 0.9589\n",
            "\n",
            "CNN: Test accuracy: 0.6694999933242798\n",
            "\n",
            "ResNet: Test Accuracy: 0.7167999744415283\n"
          ]
        }
      ]
    }
  ]
}